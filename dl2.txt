# %%
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM

# %%
top_words = 10000
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)

# %%
max_length = 300
X_train = pad_sequences(X_train, maxlen=max_length)
X_test = pad_sequences(X_test, maxlen=max_length)

# %%
X_train.shape
# print("Training data: ",X_train)

# %%
# create the model
model = Sequential()
model.add (Embedding (input_dim = top_words,output_dim= 128, input_length=max_length))
model.add(LSTM(64))
model.add (Dense(1, activation='sigmoid'))

#model Compile
model.compile (loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# %%
# Fit the model
history = model.fit(X_train, y_train, epochs=2,validation_split=0.2, verbose=2)

# %%
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

# %% [markdown]
# 782/782 [==============================] - 53s 68ms/step - loss: 0.3640 - accuracy: 0.8650
# Test Loss: 0.363955557346344
# Test Accuracy: 0.8649600148200989


